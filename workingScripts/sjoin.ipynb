{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating place name based on county bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction\n",
    "This Jupyter Notebook is intended to find the spatial coverage based on bounding box. It is a reverse version of **<a href='https://github.com/BTAA-Geospatial-Data-Project/geonames'>geonames</a>**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preparation\n",
    "We will be using **Jupyter Notebook(anaconda 3)** to edit and run the script. Information on Anaconda installation can be found <a href='https://docs.anaconda.com/anaconda/install/'>here</a>. Please note that this script is running on Python 3.\n",
    "\n",
    "Before running the script, you may need to:\n",
    "### 1. Run other two Jupyter Notebooks\n",
    "- If the target state(s) hasn't been converted into city or county bounding box file, you may need to run `city_bbox.ipynb` or `county_bbox.ipynb` or `merge_geojson.ipynb` first.  \n",
    "\n",
    "### 2. Restructure Directories\n",
    "- ***sjoin.ipynb***\n",
    "- ***city_bbox.ipynb***\n",
    "- ***county_bbox.ipynb***\n",
    "- ***merge_geojson.ipynb***\n",
    "- **geojson** folder\n",
    "    - **state1** foloder\n",
    "        - ***state1_County_bbox.json***\n",
    "        - ***state1_City_bbox.json***\n",
    "    - **state2** foloder\n",
    "        - ***state2_County_bbox.json***\n",
    "        - ***state2_City_bbox.json***\n",
    "    - ...\n",
    "- **data** folder\n",
    "    - **code** foloder\n",
    "        - ***code.csv*** formatted in GBL Metadata Template\n",
    "        - ***state_bbox.json*** and/or **state1_state2_....json**\n",
    "        \n",
    "### 3. Inspect `code.csv`\n",
    "If records belong to regional data portal, you probably need to create merged county bounding box file. \n",
    "\n",
    "The final product would be one CSV file named ***code_placename.csv***. \n",
    "\n",
    "> Original created on Jan 31 2021 <br>\n",
    "> @author: Yijing Zhou @YijingZhou33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import json\n",
    "from shapely.geometry import box\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Manual items to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'Merged'\n",
    "\n",
    "###### Rawdata comes from state data portal -- single state #####\n",
    "\n",
    "# **************** uncomment **********************\n",
    "# csvname = 'Maryland'\n",
    "# gjsoname = 'Maryland_bbox'\n",
    "# *************************************************\n",
    "\n",
    "###### Rawdata comes from regional data portal -- multiple states #####\n",
    "\n",
    "# **************** uncomment **********************\n",
    "csvname = '4f-01'\n",
    "gjsoname = 'ML_PA_NJ_DE_bbox'\n",
    "# *************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Set file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = os.path.join('data', code, csvname + '.csv')\n",
    "basemap = os.path.join('data', code, gjsoname + '.json')\n",
    "output = os.path.join('data', code, csvname + '_placename.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Build up GeoJSON dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create bounding box for csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Coordinates --> Identifier:  498997b99f0042a3aa9c4aba8a79a30d_0\n",
      "Wrong Coordinates --> Identifier:  4d360675145241f691e8d3655de2b287_0\n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv(rawdata)\n",
    "\n",
    "def format_coordinates(df, identifier):\n",
    "    ## create regular bouding box coordinate pairs and round them to 1 decimal places\n",
    "    df = pd.concat([df, df['Bounding Box'].str.split(',', expand=True).astype(float).round(2)], axis=1).rename(\n",
    "        columns={0:'minX', 1:'minY', 2:'maxX', 3:'maxY'})\n",
    "    \n",
    "    ## check if there exists wrong coordinates\n",
    "    for _, row in df.iterrows():\n",
    "        if (row.maxX - row.minX) > 10 or (row.maxY - row.minY) > 10 or (row.minX < -100):\n",
    "            print('Wrong Coordinates --> Identifier: ', row[identifier])\n",
    "    \n",
    "    ## create bouding box\n",
    "    df['Coordinates'] = df.apply(lambda row: box(row.minX, row.minY, row.maxX, row.maxY), axis=1)\n",
    "    \n",
    "    ## clean up unnecessary columns\n",
    "    return df.drop(columns =['minX', 'minY', 'maxX', 'maxY'])\n",
    "\n",
    "df_clean = format_coordinates(df_csv, 'layer_slug_s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Convert csv and GeoJSON file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf_rawdata = gpd.GeoDataFrame(df_clean, geometry = df_clean['Coordinates'])\n",
    "gdf_rawdata.crs = 'EPSG:4326'\n",
    "\n",
    "gdf_county = gpd.read_file(basemap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Spatial Join\n",
    "**<a href='https://geopandas.org/reference/geopandas.sjoin.html#geopandas-sjoin'>`geopandas.sjoin`</a>** provides the following the criteria used to match rows:\n",
    "- intersects \n",
    "- within\n",
    "- contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_join(identifier):\n",
    "    dflist = []\n",
    "    operations = ['intersects', 'within', 'contains']\n",
    "    for op in operations:\n",
    "        df_merged = gpd.sjoin(gdf_rawdata, gdf_county, op = op, how = 'left')[[identifier, 'County', 'State']].astype(str)\n",
    "        ## merge column 'County' and 'State' into one 'County, State'\n",
    "        df_merged['County'] = df_merged[['County', 'State']].agg(', '.join, axis=1).replace('nan, nan', 'nan')\n",
    "        ## group records by identifier\n",
    "        df_group = df_merged.drop(columns = ['State']).reset_index(drop = True).groupby(identifier\n",
    "                    )['County'].apply(list).reset_index(name = op)\n",
    "        ## replace ['nan'] with None\n",
    "        df_group[op] = df_group[op].apply(lambda row: None if row[0] == 'nan' else row)\n",
    "        dflist.append(df_group.rename(columns={'County': op}))\n",
    "    \n",
    "    ## merge dataframes created by different match options\n",
    "    df_sjoin = reduce(lambda left,right: pd.merge(left, right, on = identifier, how = 'outer'), dflist)\n",
    "    \n",
    "    return gdf_rawdata.merge(df_sjoin, on = identifier).drop(columns =['Coordinates', 'geometry'])\n",
    "\n",
    "df_comparison = spatial_join('layer_slug_s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Populate place names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## e.g. ['Camden County, New Jersey', 'Delaware County, Pennsylvania', 'Philadelphia County, Pennsylvania']\n",
    "def format_placename(colname):\n",
    "    inv_map = {}\n",
    "    plist = []\n",
    "    \n",
    "    ## {'Camden County': 'New Jersey', 'Delaware County': 'Pennsylvania', 'Philadelphia County': 'Pennsylvania'}\n",
    "    namedict = dict(item.split(', ') for item in colname)\n",
    "\n",
    "    ## {'New Jersey': ['Camden County'], 'Pennsylvania': ['Delaware County', 'Philadelphia County']}\n",
    "    for k, v in namedict.items():\n",
    "        inv_map[v] = inv_map.get(v, []) + [k] \n",
    "    \n",
    "    ## ['Camden County, New Jersey|New Jersey', 'Delaware County, Pennsylvania|Philadelphia County, Pennsylvania|Pennsylvania']\n",
    "    for k, v in inv_map.items():\n",
    "        pname = [elem + ', ' + k for elem in v]\n",
    "        pname.append(k)\n",
    "        plist.append('|'.join(pname))\n",
    "\n",
    "    ## Camden County, New Jersey|New Jersey|Delaware County, Pennsylvania|Philadelphia County, Pennsylvania|Pennsylvania\n",
    "    return '|'.join(plist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def populate_placename(df, identifier):\n",
    "    placenamelist = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['within'] is None:\n",
    "            ## no within feature && <= 5 contain features --> contains features\n",
    "            if row['contains'] is not None and len(row['contains']) < 6:\n",
    "                placename = format_placename(row['contains'])\n",
    "            ## no intersect, within (and contains) feature --> wrong coordinates\n",
    "            elif row['intersects'] is None:\n",
    "                placename = ''\n",
    "            ## > 3 contain features --> state\n",
    "            else:\n",
    "                statedict = dict(item.split(', ') for item in row['intersects']) \n",
    "                placename = ('|').join(set([v for k, v in statedict.items()]))\n",
    "        else:\n",
    "            ## otherwise, within features\n",
    "            placename = format_placename(row['within'])\n",
    "        placenamelist.append(placename)\n",
    "    \n",
    "    df['Place Name'] = placenamelist\n",
    "    df_final = df.drop(columns = ['intersects', 'within', 'contains'])\n",
    "    df_final.to_csv(output, index = False)\n",
    "\n",
    "populate_placename(df_comparison, 'layer_slug_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
